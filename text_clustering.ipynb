{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDocuments(doc_file):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    with open(doc_file,encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label,_,_,doc = line.strip().split(maxsplit=3)\n",
    "            docs.append(doc)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return docs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def purity(labels, clustered):\n",
    "    \n",
    "    #* find the set of cluster ids\n",
    "    cluster_ids = set(clustered)\n",
    "    \n",
    "    N = len(clustered)\n",
    "    majority_sum = 0\n",
    "    \n",
    "    for cl in cluster_ids:\n",
    "        \n",
    "        #* for this cluster, we compute the frequencies of the different human labels we encounter \n",
    "        #* the result will be something like {'camera':5, 'books':1,'software':3} etc \n",
    "        labels_cl = Counter(l for l,c in zip(labels,clustered) if c==cl)\n",
    "        \n",
    "        #* We select the highest score and add it to the total sum \n",
    "        majority_sum += max(labels_cl.values())\n",
    "        \n",
    "        \n",
    "    #* The purity score is the sum of majority counts divided by the total number of items \n",
    "    return majority_sum/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('music',\n",
       " 'i was misled and thought i was buying the entire cd and it contains one song')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs, labels = readDocuments('text_to_cluster.txt')\n",
    "labels[1],docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "doc_matrix = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 46619)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters=7,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 22649.405654497605.\n",
      "Iteration 1, inertia 11645.64819270793.\n",
      "Iteration 2, inertia 11583.280634563964.\n",
      "Iteration 3, inertia 11567.178491705683.\n",
      "Iteration 4, inertia 11559.135645371907.\n",
      "Iteration 5, inertia 11556.143446157923.\n",
      "Iteration 6, inertia 11553.856896596888.\n",
      "Iteration 7, inertia 11552.342369276237.\n",
      "Iteration 8, inertia 11551.205964062436.\n",
      "Iteration 9, inertia 11550.3279566428.\n",
      "Iteration 10, inertia 11549.466110412322.\n",
      "Iteration 11, inertia 11548.574437187888.\n",
      "Iteration 12, inertia 11547.566463701593.\n",
      "Iteration 13, inertia 11546.659999086829.\n",
      "Iteration 14, inertia 11545.978772510034.\n",
      "Iteration 15, inertia 11545.596583057883.\n",
      "Iteration 16, inertia 11545.346095437622.\n",
      "Iteration 17, inertia 11545.177157191605.\n",
      "Iteration 18, inertia 11545.05968233712.\n",
      "Iteration 19, inertia 11544.9489254939.\n",
      "Iteration 20, inertia 11544.851695378607.\n",
      "Iteration 21, inertia 11544.773638596103.\n",
      "Iteration 22, inertia 11544.696777730489.\n",
      "Iteration 23, inertia 11544.617212705252.\n",
      "Iteration 24, inertia 11544.531983074063.\n",
      "Iteration 25, inertia 11544.4274681913.\n",
      "Iteration 26, inertia 11544.284748577498.\n",
      "Iteration 27, inertia 11544.157246682365.\n",
      "Iteration 28, inertia 11544.057801686264.\n",
      "Iteration 29, inertia 11543.98939171536.\n",
      "Iteration 30, inertia 11543.91494952927.\n",
      "Iteration 31, inertia 11543.856465690491.\n",
      "Iteration 32, inertia 11543.809476392053.\n",
      "Iteration 33, inertia 11543.771267840559.\n",
      "Iteration 34, inertia 11543.728155435769.\n",
      "Iteration 35, inertia 11543.679449038873.\n",
      "Iteration 36, inertia 11543.60838587558.\n",
      "Iteration 37, inertia 11543.513854024928.\n",
      "Iteration 38, inertia 11543.361500346386.\n",
      "Iteration 39, inertia 11543.094845159721.\n",
      "Iteration 40, inertia 11542.391141084372.\n",
      "Iteration 41, inertia 11540.373894991146.\n",
      "Iteration 42, inertia 11538.80550610105.\n",
      "Iteration 43, inertia 11538.681544238767.\n",
      "Iteration 44, inertia 11538.641828321015.\n",
      "Iteration 45, inertia 11538.621240231478.\n",
      "Iteration 46, inertia 11538.61092960231.\n",
      "Iteration 47, inertia 11538.608248921732.\n",
      "Iteration 48, inertia 11538.606347809678.\n",
      "Iteration 49, inertia 11538.605459889794.\n",
      "Converged at iteration 49: strict convergence.\n"
     ]
    }
   ],
   "source": [
    "clustered_docs = clusterer.fit(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 22843.45488304372.\n",
      "Iteration 1, inertia 11649.19908114195.\n",
      "Iteration 2, inertia 11573.103364292014.\n",
      "Iteration 3, inertia 11545.293387540625.\n",
      "Iteration 4, inertia 11539.139768945199.\n",
      "Iteration 5, inertia 11537.004431983336.\n",
      "Iteration 6, inertia 11535.901061448298.\n",
      "Iteration 7, inertia 11535.325428447106.\n",
      "Iteration 8, inertia 11535.00433776055.\n",
      "Iteration 9, inertia 11534.819136798666.\n",
      "Iteration 10, inertia 11534.672136687424.\n",
      "Iteration 11, inertia 11534.525797389731.\n",
      "Iteration 12, inertia 11534.437648002187.\n",
      "Iteration 13, inertia 11534.351915640193.\n",
      "Iteration 14, inertia 11534.2726518539.\n",
      "Iteration 15, inertia 11534.173487349346.\n",
      "Iteration 16, inertia 11534.04106837898.\n",
      "Iteration 17, inertia 11533.898468648014.\n",
      "Iteration 18, inertia 11533.784015867637.\n",
      "Iteration 19, inertia 11533.711565940388.\n",
      "Iteration 20, inertia 11533.68273125722.\n",
      "Iteration 21, inertia 11533.662652059285.\n",
      "Iteration 22, inertia 11533.651782916606.\n",
      "Iteration 23, inertia 11533.64098218174.\n",
      "Iteration 24, inertia 11533.63253462234.\n",
      "Iteration 25, inertia 11533.622546922792.\n",
      "Iteration 26, inertia 11533.615849257716.\n",
      "Iteration 27, inertia 11533.606727328897.\n",
      "Iteration 28, inertia 11533.600090683894.\n",
      "Iteration 29, inertia 11533.592891127957.\n",
      "Iteration 30, inertia 11533.586796978225.\n",
      "Iteration 31, inertia 11533.585960079148.\n",
      "Iteration 32, inertia 11533.585098874773.\n",
      "Iteration 33, inertia 11533.581741490521.\n",
      "Iteration 34, inertia 11533.578893605107.\n",
      "Iteration 35, inertia 11533.576067203936.\n",
      "Iteration 36, inertia 11533.573551168378.\n",
      "Iteration 37, inertia 11533.57265605902.\n",
      "Iteration 38, inertia 11533.570774897522.\n",
      "Iteration 39, inertia 11533.569014366458.\n",
      "Iteration 40, inertia 11533.568143452834.\n",
      "Iteration 41, inertia 11533.567297798465.\n",
      "Converged at iteration 41: strict convergence.\n"
     ]
    }
   ],
   "source": [
    "clustered_docs = clusterer.fit_predict(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6653516870908175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity(labels,clustered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3073981690353386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "adjusted_rand_score(labels,clustered_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets first define a distilBERT Transformer using Huggingface sytle code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer\n",
    "import torch.nn as nn \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, checkpoint, freeze=False,device='cuda'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(checkpoint) #* path to the desired model \n",
    "        hidden_sz = self.model.config.hidden_size\n",
    "        \n",
    "        # set device cuda or cpu \n",
    "        self.device = device \n",
    "        \n",
    "        #* freeze model \n",
    "        if freeze:\n",
    "            for layer in self.model.parameters():\n",
    "                layer.requires_grad = False\n",
    "                \n",
    "    def forward(self,x,attention_mask=None):\n",
    "        \n",
    "        x = x.to(self.device)\n",
    "        #* pooler_output(seq,dim)\n",
    "        with torch.no_grad():\n",
    "            model_out = self.model(x['input_ids'], x['attention_mask'],return_dict = True)\n",
    "            \n",
    "        embds = model_out.last_hidden_state # model_out[0][:,0]\n",
    "        mean_pool = embds.sum(axis=1)/x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        return mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 483/483 [00:00<?, ?B/s] \n",
      "c:\\Users\\atesb\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\atesb\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:33<00:00, 7.98MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 27.3kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 795kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 3.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 'distilbert-base-uncased'\n",
    "distilbert = Model(checkpoint=checkpoint,freeze=True)\n",
    "distilbert.to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embeddings = list()\n",
    "all_embeddings = []\n",
    "\n",
    "final_sentences = docs\n",
    "\n",
    "batch_size = 200\n",
    "for idx in range(0,len(final_sentences),batch_size):\n",
    "    batch_sentences = final_sentences[idx:idx+batch_size]\n",
    "    for sent in batch_sentences:\n",
    "        tokens = tokenizer(sent,truncation='longest_first',return_tensors='pt',return_attention_mask=True,padding=True)\n",
    "        embedding = distilbert(tokens)\n",
    "        final_embeddings.extend(embedding)\n",
    "        all_embeddings = torch.stack(final_embeddings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 153052.2008887094.\n",
      "Iteration 1, inertia 100596.89611935118.\n",
      "Iteration 2, inertia 98634.30119654113.\n",
      "Iteration 3, inertia 97333.19172882223.\n",
      "Iteration 4, inertia 96584.58026631159.\n",
      "Iteration 5, inertia 96316.3166051021.\n",
      "Iteration 6, inertia 96209.70803980563.\n",
      "Iteration 7, inertia 96148.79743364117.\n",
      "Iteration 8, inertia 96108.32295662361.\n",
      "Iteration 9, inertia 96077.6633120169.\n",
      "Iteration 10, inertia 96048.50767093543.\n",
      "Iteration 11, inertia 96020.20751152062.\n",
      "Iteration 12, inertia 95998.29192750846.\n",
      "Iteration 13, inertia 95981.08595031193.\n",
      "Iteration 14, inertia 95967.57356690906.\n",
      "Iteration 15, inertia 95957.60629427517.\n",
      "Iteration 16, inertia 95949.69181953414.\n",
      "Iteration 17, inertia 95944.19594439716.\n",
      "Iteration 18, inertia 95941.29084667818.\n",
      "Iteration 19, inertia 95939.92474811812.\n",
      "Iteration 20, inertia 95939.40020773059.\n",
      "Iteration 21, inertia 95938.76313925209.\n",
      "Iteration 22, inertia 95938.21318149686.\n",
      "Iteration 23, inertia 95937.89436141809.\n",
      "Iteration 24, inertia 95937.30708093595.\n",
      "Iteration 25, inertia 95936.62819780769.\n",
      "Iteration 26, inertia 95936.28235835061.\n",
      "Iteration 27, inertia 95936.16136196602.\n",
      "Iteration 28, inertia 95936.06818323774.\n",
      "Iteration 29, inertia 95936.0152757564.\n",
      "Iteration 30, inertia 95935.96159460282.\n",
      "Iteration 31, inertia 95935.91228860866.\n",
      "Iteration 32, inertia 95935.83865955041.\n",
      "Iteration 33, inertia 95935.79274108492.\n",
      "Iteration 34, inertia 95935.77529038239.\n",
      "Iteration 35, inertia 95935.76111845288.\n",
      "Iteration 36, inertia 95935.75139819717.\n",
      "Converged at iteration 36: strict convergence.\n"
     ]
    }
   ],
   "source": [
    "clustered_docs = clusterer.fit_predict(all_embeddings.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7824408259190868"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity(labels,clustered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5507564962031405"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score(labels,clustered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
